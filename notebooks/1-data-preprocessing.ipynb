{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CompOmics/lsabd-machine-learning-tutorials/blob/main/notebooks/1-data-preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7M5B6XEim8LF"
   },
   "source": [
    "# Data preprocessing for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore the basics of data preprocessing for machine learning using the breast cancer dataset from scikit-learn. We will cover loading the dataset, understanding its structure, handling missing values, and scaling features. \n",
    "\n",
    "Note that throughout the notebook, there are links to the relevant documentation for the functions and classes used. Click on the links and explore the documentation to deepen your understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMdNcp8pm8LG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the style for our visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjkaxLkNm8LH"
   },
   "source": [
    "## Loading a dataset\n",
    "\n",
    "The breast cancer dataset is a classic dataset in machine learning. It contains features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. These features describe characteristics of the cell nuclei present in the image.\n",
    "\n",
    "Learn more about the dataset in the [original paper](https://doi.org/10.1016/0304-3835(94)90099-X) and on the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic).\n",
    "\n",
    "Normally, we load datasets from a file using functions like [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). However, this dataset is so often used in tutorials, that it has been included in the [`sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) library. Let's load it and take a look at its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_dataset = datasets.load_breast_cancer(as_frame=True)\n",
    "cancer_dataset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loaded, the dataset is represented as a dictionary-like object with several attributes. The main attributes are:\n",
    "- `data`: A 2D array where each row represents an instance (a breast mass) and each column represents a feature.\n",
    "- `target`: A 1D array containing the target variable, indicating whether the cancer is malignant (0) or benign (1).\n",
    "- `feature_names`: An array of strings representing the names of the features.\n",
    "- `target_names`: An array of strings representing the names of the target classes.\n",
    "\n",
    "Note that we used the `as_frame=True` parameter when loading the dataset. The feature table is returned as a pandas [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#dataframe), which provides convenient methods for data manipulation and analysis. The target variable is also returned as a pandas Series, which can be regarded as a single column.\n",
    "\n",
    "The `data` attribute allows us to access the feature values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cancer_dataset.data\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `target` attribute provides the labels for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = cancer_dataset.target\n",
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question: How many samples and features are in the breast cancer dataset?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bonus Python refresher question: What is the difference between calling a property with parentheses (e.g., `features.head()`) and without parentheses (e.g., `cancer_dataset.target`)?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhtJ4arvm8LI"
   },
   "source": [
    "## Exploring the dataset\n",
    "\n",
    "### Exploring the features\n",
    "\n",
    "First and foremost, it's important to understand the structure and characteristics of the features. This includes checking for missing values, understanding the data types (numerical, categorical), and getting a sense of the distribution of the features.\n",
    "\n",
    "The Pandas [`dtypes`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html) property allows us to check the data types of each feature in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains only numerical features (float values), so we do not need to handle categorical variables. If this would be the case, we could use techniques such as one-hot encoding or label encoding to convert categorical variables into numerical format. You can learn more about these techniques in the [Encoding categorical features](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features) section of the Scikit-learn user Guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas `isnull()` method can be used to check for missing values in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucky again, this dataset does not contain any missing values. If there would be, Scikit-learn provides several options for handling missing values, as described in the [Handling missing values](https://scikit-learn.org/stable/modules/impute.html) section of User Guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use pandas methods such as `describe()` to get an overview of the numerical features. Adding `.T` at the end transposes the output for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This summary provides us with some basic statistics about each feature, such as the mean, standard deviation, minimum, and maximum values. However, it is a bit hard to read. Alternatively, we can visualize the distribution of each feature using box plots. For this, we'll use the Seaborn [`boxplot`](https://seaborn.pydata.org/generated/seaborn.boxplot.html) function.\n",
    "\n",
    "*Detail:* Because the boxplot function expects the data in a long format, we first use the pandas [`melt`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.melt.html) method to reshape the DataFrame. You can read more about long vs wide data formats in the [Pandas User Guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#melt-and-wide-to-long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=features.melt(), x=\"value\", y=\"variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question: What is immediate obvious from the box plots about the features in the dataset? Are there any features that stand out from the others?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These general distribution plots do not show the relationship between the features and the target variable. To explore this, we can create box plots for each feature, grouped by the target variable (malignant vs benign). This will help us understand how the features differ between the two classes.\n",
    "\n",
    "For instance, let's take a look at the `mean radius` feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_radius_df = pd.DataFrame(\n",
    "    {\"mean radius\": features[\"mean radius\"], \"target\": targets}\n",
    ")\n",
    "\n",
    "sns.boxplot(data=mean_radius_df, x=\"mean radius\", hue=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can get a more detailed view of the distribution using histograms.\n",
    "\n",
    "*Task: Try it out with the Seaborn [`histplot`](https://seaborn.pydata.org/generated/seaborn.histplot.html) function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the histplot function to visualize the feature distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question: What do you think about the distribution of the `mean radius` feature for malignant vs benign tumors? Would this be a useful feature for classification?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task: Repeat the above analysis (box plots and histograms) for at least two other features of your choice from the dataset. Summarize your findings.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your findings here:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the target variable\n",
    "\n",
    "The target variable indicates whether the breast mass is malignant or benign. We can use the Pandas [`value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) method to see the distribution of the target classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize this distribution using a bar plot with the Seaborn [`countplot`](https://seaborn.pydata.org/generated/seaborn.countplot.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y=targets, orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question: What do you observe about the class distribution? Is the dataset balanced or imbalanced? How might this impact model training and evaluation?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiCl_l0Fm8LI"
   },
   "source": [
    "## Data splitting\n",
    "\n",
    "In machine learning, it is crucial to evaluate the performance of our models on unseen data. To achieve this, we typically split our dataset into training and testing sets. The training set is used to train the model, while the testing set is used to evaluate its performance. In real-world scenarios, we might also use a validation set for hyperparameter tuning. For now, we will focus on a simple train-test split.\n",
    "\n",
    "This can be done easily using the [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function from the [`sklearn.model_selection`](https://scikit-learn.org/stable/api/sklearn.model_selection.html) module. By default, it splits the data into 75% training and 25% testing sets, but we can adjust this ratio using the `test_size` parameter. The function allows us to pass multiple arrays (e.g., features and target) and splits them consistently; i.e., the corresponding rows in the features and target arrays remain aligned after the split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some datasets contain both features and targets within a single table. In such cases, it is crucial to separate them before proceeding with your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vn8Y5uGVm8LI"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_targets, test_targets = train_test_split(\n",
    "    features, targets, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {train_features.shape}\")\n",
    "print(f\"Testing set shape: {test_features.shape}\")\n",
    "\n",
    "print(\n",
    "    f\"Percent positives in training set: {train_targets.value_counts(normalize=True)[1]:.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Percent positives in testing set: {test_targets.value_counts(normalize=True)[1]:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question: What does the `random_state` parameter do in the `train_test_split` function? Why is it important to set it?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for class imbalance during the split, we can choose use the `stratify` parameter. By setting it to the target variable, we ensure that the proportion of classes in both the training and testing sets reflects that of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_targets, test_targets = train_test_split(\n",
    "    features, targets, test_size=0.3, random_state=42, stratify=targets\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {train_features.shape}\")\n",
    "print(f\"Testing set shape: {test_features.shape}\")\n",
    "\n",
    "print(\n",
    "    f\"Percent positives in training set: {train_targets.value_counts(normalize=True)[1]:.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Percent positives in testing set: {test_targets.value_counts(normalize=True)[1]:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question: After performing the stratified split, do you see a difference in the percentage of positive classes compared to the initial split? Why is this the case? When would it not be the case?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbNHXTn2m8LJ"
   },
   "source": [
    "## Feature scaling\n",
    "\n",
    "Many machine learning algorithms are sensitive to the scale of the input features. Features with larger scales can dominate the learning process, leading to suboptimal performance. To address this, we often apply feature scaling techniques to standardize or normalize the features.\n",
    "\n",
    "As we saw earlier, the features in the breast cancer dataset have varying scales. For instance, the `mean radius` feature ranges from approximately 6 to 30, while the `worst area` feature ranges from about 200 to 2500. To ensure that all features contribute equally to the learning process, we can apply feature scaling.\n",
    "\n",
    "Here, we will cover two common scaling techniques: Standardization and Min-Max Scaling. You can learn more about these techniques in the [scikit-learn User Guide](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hPMt5xmm8LJ"
   },
   "source": [
    "### Standardization using `StandardScaler`\n",
    "\n",
    "The [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) class standardizes features by removing the mean and scaling to unit variance. This means that the resulting distribution of each feature will have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IskSSFlgm8LJ"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_features)\n",
    "train_features_standardized_array = scaler.transform(train_features)\n",
    "test_features_standardized_array = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used two steps to apply the `StandardScaler`:\n",
    "\n",
    "1. **Fit the scaler on the training data**: This computes the mean and standard deviation for each feature in the training set.\n",
    "2. **Transform both the training and testing data**: This applies the scaling using the parameters computed from the training set.\n",
    "\n",
    "It is crucial to fit the scaler only on the training data to avoid data leakage. Data leakage occurs when information from the test set is used to inform the training process, leading to overly optimistic performance estimates. While it might not seem intuitive, this also applies to scaling techniques. Scaling always takes place **after** the data splitting.\n",
    "Never do:\n",
    "\n",
    "```python\n",
    "scaler.fit(features)  # Incorrect: fitting on the entire dataset\n",
    "scaled_features = scaler.transform(features)\n",
    "```\n",
    "\n",
    "\n",
    "To simplify your code, sklearn provides a `fit_transform` method that combines both fitting and transforming in one step for the training data. However, remember to use the `transform` method separately for the test data.\n",
    "\n",
    "*Task: Repeat the entire process in the previous code cell, but using the `fit_transform` method for the training data. Make sure to use the correct methods on the correct data sets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for the full standardization process using fit_transform and transform methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these functions return NumPy arrays. To convert them back to pandas DataFrames for easier handling, we can use the following approach, where we also retain the original column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_standardized = pd.DataFrame(\n",
    "    train_features_standardized_array, columns=train_features.columns\n",
    ")\n",
    "test_features_standardized = pd.DataFrame(\n",
    "    test_features_standardized_array, columns=test_features.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the effect of standardization, let's visualize the distribution of a feature before and after scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(12, 8), ncols=2)\n",
    "\n",
    "sns.boxplot(data=train_features.melt(), x=\"value\", y=\"variable\", ax=axes[0])\n",
    "axes[0].set_title(\"before standardization\")\n",
    "\n",
    "sns.boxplot(\n",
    "    data=train_features_standardized.melt(), x=\"value\", y=\"variable\", ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"after standardization\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature distributions already look more comparable after standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qosyr9Ntm8LJ"
   },
   "source": [
    "### Scaling features between 0 and 1 using `MinMaxScaler`\n",
    "\n",
    "The `MinMaxScaler` scales features to a specified range, typically between 0 and 1. This is done by subtracting the minimum value of each feature and then dividing by the range (max - min). The resulting values will be within the specified range. The scikit-learn [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) class provides a similar interface to the `StandardScaler`.\n",
    "\n",
    "*Task: Repeat the entire scaling process using the `MinMaxScaler`. Visualize the feature distributions before and after scaling, similar to what we did for the `StandardScaler`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the code for the full scaling process using fit_transform and transform methods.\n",
    "# Ensure to end up with DataFrames for both train and test sets in the variables:\n",
    "# - train_features_scaled\n",
    "# - test_features_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the distribution of the features before and after scaling for both scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(12, 8), ncols=3)\n",
    "\n",
    "sns.boxplot(data=train_features.melt(), x=\"value\", y=\"variable\", ax=axes[0])\n",
    "axes[0].set_title(\"before\")\n",
    "\n",
    "sns.boxplot(\n",
    "    data=train_features_standardized.melt(), x=\"value\", y=\"variable\", ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"after standardization\")\n",
    "\n",
    "sns.boxplot(data=train_features_scaled.melt(), x=\"value\", y=\"variable\", ax=axes[2])\n",
    "axes[2].set_title(\"after min-max scaling\")\n",
    "\n",
    "# Hide repeated y-axis label and tick labels on the middle and right plots\n",
    "for idx in [1, 2]:\n",
    "    axes[idx].set_ylabel(\"\")\n",
    "    axes[idx].tick_params(labelleft=False, left=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question: Based on the box plots, how do the feature distributions differ after applying standardization and min-max scaling? What about outliers?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler is preferred for most ML algorithms (logistic regression, SVM, neural networks) that assume normally distributed data. It transforms features to have mean=0 and standard deviation=1, preserves the original distribution shape, and handles outliers better, though values remain unbounded.\n",
    "\n",
    "MinMaxScaler is necessary when you need features bounded to [0, 1], particularly for neural networks with bounded activation functions (sigmoid, tanh) where matching input/output scales improves convergence, or algorithms like k-NN that don't assume any distribution. However, it's sensitive to outliersâ€”a single extreme value can compress all other values.\n",
    "\n",
    "Start with StandardScaler for linear models and SVMs; use MinMaxScaler when you specifically need bounded ranges or work with neural networks. Tree-based models (Random Forest, XGBoost) don't require scaling at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a simple model\n",
    "\n",
    "The dataset is now ready for training machine learning models! Here's a sneak peek of a simple\n",
    "classification model using the logistic regression algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(train_features_scaled, train_targets)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = model.predict(test_features_scaled)\n",
    "\n",
    "# Generate the classification report\n",
    "print(\n",
    "    classification_report(\n",
    "        test_targets, test_predictions, target_names=cancer_dataset.target_names\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion_mat = confusion_matrix(test_targets, test_predictions)\n",
    "sns.heatmap(\n",
    "    confusion_mat,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=cancer_dataset.target_names,\n",
    "    yticklabels=cancer_dataset.target_names,\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a pipeline for preprocessing and modeling\n",
    "\n",
    "To streamline the preprocessing and modeling steps, we can use a Scikit-learn [`Pipeline`](https://scikit-learn.org/stable/modules/compose.html#pipeline-chaining-estimators). A pipeline allows us to chain multiple processing steps together, ensuring that the same transformations are applied consistently during both training and testing. Crucially, it also helps prevent data leakage by encapsulating the entire workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(),\n",
    ")\n",
    "pipeline.fit(train_features, train_targets)\n",
    "preds = pipeline.predict(test_features)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lsabd-machine-learning-tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
